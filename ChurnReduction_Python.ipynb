{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "from ggplot import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\DS_New\\Project 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_data.csv\")\n",
    "test = pd.read_csv(\"Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate Analysis\n",
    "df = df.drop('phone number', axis = 1)\n",
    "df['area code'] = df['area code'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning levels to categorical variables\n",
    "for i in range(0, df.shape[1]):\n",
    "    if(df.iloc[:,i].dtypes == 'object'):\n",
    "        df.iloc[:,i] = pd.Categorical(df.iloc[:,i])\n",
    "        df.iloc[:,i] = df.iloc[:,i].cat.codes \n",
    "        df.iloc[:,i] = df.iloc[:,i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Value Analysis\n",
    "miss_val = pd.DataFrame(df.isnull().sum())\n",
    "miss_val = miss_val.reset_index()\n",
    "miss_val = miss_val.rename(columns = {'index': 'Predictors', 0: 'Missing_Percentage'})\n",
    "miss_val['Missing_Percentage'] = (miss_val['Missing_Percentage']/len(df))*100\n",
    "miss_val = miss_val.sort_values('Missing_Percentage', ascending = False).reset_index(drop = True)\n",
    "print(miss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nm = []\n",
    "cat_nm = []\n",
    "for i in range(0, df.shape[1]):\n",
    "        if(df.iloc[:,i].dtypes == 'object'):\n",
    "            cat_nm.append(df.columns[i])\n",
    "        else:\n",
    "            num_nm.append(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Boxplot\n",
    "ggplot(df, aes(x = 'Churn', y = 'account length', fill = 'Churn')) +\\\n",
    "  geom_boxplot(fill = 'Churn') +\\\n",
    "  ylab(\"Account Length\") + xlab(\"Churn\") + ggtitle(\"Outlier Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "ggplot(df, aes(x = 'account length')) + geom_histogram(fill=\"DarkSlateBlue\", colour = \"black\") +\\\n",
    "    geom_density() +\\\n",
    "    theme_bw() + xlab(\"Account Length\") + ylab(\"Frequency\")  +\\\n",
    "    theme(text=element_text(size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Outliers with NA\n",
    "for i in num_nm:\n",
    "     print(i)\n",
    "     q75, q25 = np.percentile(df.loc[:,i], [75 ,25])\n",
    "     iqr = q75 - q25\n",
    "     min = q25 - (iqr*1.5)\n",
    "     max = q75 + (iqr*1.5)\n",
    "     print(min)\n",
    "     print(max)\n",
    "     df.loc[df.loc[:,i] < min,i] = np.nan\n",
    "     df.loc[df.loc[:,i] > max,i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Best Method\n",
    "#Please uncomment and comment as necessary to test\n",
    "df_test['total day minutes'].loc[70] \n",
    "#Original = 241.8\n",
    "#With Mean = 179.92\n",
    "#With Median = 179.4\n",
    "#With KNN = 207.02\n",
    "df_test['total day minutes'].loc[70] = np.nan\n",
    "df_test['total day minutes'] = df_test['total day minutes'].fillna(df_test['total day minutes'].mean())\n",
    "df_test['total day minutes'] = df_test['total day minutes'].fillna(df_test['total day minutes'].median())\n",
    "df_test = pd.DataFrame(KNN(k = 3).complete(df_test), columns = df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the NaN values with KNN -- Chosen\n",
    "df = pd.DataFrame(KNN(k = 3).complete(df), columns = df.columns)\n",
    "#Median\n",
    "#for i in num_nm:\n",
    "#    df.loc[:,i]= df.loc[:,i].fillna(df.loc[:,i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Heatmap\n",
    "num_dt = df.loc[:, num_nm]\n",
    "f, ax = plt.subplots(figsize=(7,5))\n",
    "corr_matrix = num_dt.corr()\n",
    "sns.heatmap(corr_matrix, mask=np.zeros_like(corr_matrix, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'] = df['Churn'].replace(0, 'No')\n",
    "df['Churn'] = df['Churn'].replace(1, 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assessing Variable Importance using Random Forest\n",
    "X_data = df.iloc[:,0:19]\n",
    "Y_data = df.iloc[:,19]\n",
    "rf = RandomForestClassifier(n_estimators = 1000).fit(X_data , Y_data) \n",
    "feature_importances = pd.DataFrame(rf.feature_importances_, index = X_data.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-Square Test of Independence\n",
    "for i in cat_nm:\n",
    "    print(i)\n",
    "    chi2, p, dof, ex = chi2_contingency(pd.crosstab(df['Churn'], df[i]))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['area code','account length',\n",
    "              'total night charge', 'total day charge','total eve charge','total intl charge',\n",
    "             'total day calls','total eve calls','total night calls'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nm = []\n",
    "cat_nm = []\n",
    "for i in range(0, df.shape[1]):\n",
    "        if(df.iloc[:,i].dtypes == 'object'):\n",
    "            cat_nm.append(df.columns[i])\n",
    "        else:\n",
    "            num_nm.append(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "for i in num_nm:\n",
    "    df.loc[:,i] = (df.loc[:,i] - np.min(df.loc[:,i]))/(np.max(df.loc[:,i]) - np.min(df.loc[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cleaning Test Data\n",
    "test = test.drop(['phone number','area code','account length',\n",
    "              'total night charge', 'total day charge','total eve charge','total intl charge',\n",
    "             'total day calls','total eve calls','total night calls'],axis= 1)\n",
    "for i in range(0, test.shape[1]):\n",
    "    if(test.iloc[:,i].dtypes == 'object'):\n",
    "        test.iloc[:,i] = pd.Categorical(test.iloc[:,i])\n",
    "        test.iloc[:,i] = test.iloc[:,i].cat.codes \n",
    "        test.iloc[:,i] = test.iloc[:,i].astype('object')\n",
    "\n",
    "num_nm = []\n",
    "cat_nm = []\n",
    "for i in range(0, test.shape[1]):\n",
    "        if(test.iloc[:,i].dtypes == 'object'):\n",
    "            cat_nm.append(test.columns[i])\n",
    "        else:\n",
    "            num_nm.append(test.columns[i])\n",
    "\n",
    "for i in num_nm:\n",
    "     print(i)\n",
    "     q75, q25 = np.percentile(test.loc[:,i], [75 ,25])\n",
    "     iqr = q75 - q25\n",
    "     min = q25 - (iqr*1.5)\n",
    "     max = q75 + (iqr*1.5)\n",
    "     print(min)\n",
    "     print(max)\n",
    "     test.loc[test.loc[:,i] < min,i] = np.nan\n",
    "     test.loc[test.loc[:,i] > max,i] = np.nan\n",
    "\n",
    "#Imputing with Median\n",
    "#for i in num_nm:\n",
    "#    test.loc[:,i]= test.loc[:,i].fillna(test.loc[:,i].median())\n",
    "\n",
    "#Imputing with KNN\n",
    "test = pd.DataFrame(KNN(k = 3).complete(test), columns = test.columns)\n",
    "\n",
    "for i in num_nm:\n",
    "    if(i != 'number vmail messages'):\n",
    "        test.loc[:,i] = (test.loc[:,i] - np.min(test.loc[:,i]))/(np.max(test.loc[:,i]) - np.min(test.loc[:,i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Churn'] = test['Churn'].replace(0, 'No')\n",
    "test['Churn'] = test['Churn'].replace(1, 'Yes')\n",
    "df['Churn'] = df['Churn'].replace(0, 'No')\n",
    "df['Churn'] = df['Churn'].replace(1, 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:,0:10]\n",
    "Y_train = df.iloc[:,10]\n",
    "X_test = test.iloc[:,0:10]\n",
    "Y_test = test.iloc[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "DT_model = tree.DecisionTreeClassifier(criterion = \"entropy\").fit(X_train, Y_train)\n",
    "DT_pred = DT_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating our Decision Tree Model\n",
    "CM = pd.crosstab(Y_test,DT_pred)\n",
    "AS = accuracy_score(Y_test, DT_pred)*100\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FNR = FN/(FN+TP)\n",
    "print(CM)\n",
    "print(FNR)\n",
    "print(AS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "RF_model = RandomForestClassifier(n_estimators = 1000).fit(X_train, Y_train)\n",
    "RF_pred = RF_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Random Forest\n",
    "CM = pd.crosstab(Y_test,RF_pred)\n",
    "AS = accuracy_score(Y_test, RF_pred)*100\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FNR = FN/(FN+TP)\n",
    "print(CM)\n",
    "print(FNR)\n",
    "print(AS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "#Preparing the data\n",
    "test['Churn'] = test['Churn'].replace('No', 0)\n",
    "test['Churn'] = test['Churn'].replace('Yes', 1)\n",
    "df['Churn'] = df['Churn'].replace('No', 0)\n",
    "df['Churn'] = df['Churn'].replace('Yes', 1)\n",
    "\n",
    "df_logit = pd.DataFrame(df['Churn'])\n",
    "df_logit = df_logit.join(df[num_nm])\n",
    "\n",
    "for i in cat_nm:\n",
    "    if(i != 'Churn'):\n",
    "        temp = pd.get_dummies(df[i], prefix = i)\n",
    "        df_logit = df_logit.join(temp)\n",
    "        \n",
    "test_logit = pd.DataFrame(test['Churn'])\n",
    "test_logit = test_logit.join(test[num_nm])\n",
    "\n",
    "for i in cat_nm:\n",
    "    if(i != 'Churn'):\n",
    "        temp = pd.get_dummies(test[i], prefix = i)\n",
    "        test_logit = test_logit.join(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating a Logistic Regession model\n",
    "LogR_model = sm.Logit(df_logit['Churn'], df_logit.iloc[:,1:63]).fit()\n",
    "test_logit['Actual Probability'] = LogR_model.predict(test_logit.iloc[:,1:63])\n",
    "test_logit['Actual Value'] = 1\n",
    "test_logit.loc[test_logit.loc[:,'Actual Probability'] < 0.5, 'Actual Value'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the Logistic Regression Model\n",
    "CM = pd.crosstab(test_logit['Churn'],test_logit['Actual Value'])\n",
    "AS = accuracy_score(test_logit['Churn'], test_logit['Actual Value'])*100\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FNR = FN/(FN+TP)\n",
    "print(CM)\n",
    "print(FNR)\n",
    "print(AS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "#Preparing the data\n",
    "test['Churn'] = test['Churn'].replace(0, 'No')\n",
    "test['Churn'] = test['Churn'].replace(1, 'Yes')\n",
    "df['Churn'] = df['Churn'].replace(0, 'No')\n",
    "df['Churn'] = df['Churn'].replace(1, 'Yes')\n",
    "\n",
    "X_train = df.iloc[:,0:10]\n",
    "Y_train = df.iloc[:,10]\n",
    "X_test = test.iloc[:,0:10]\n",
    "Y_test = test.iloc[:,10]\n",
    "\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 3).fit(X_train, Y_train)\n",
    "KNN_Pred = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating KNN model\n",
    "CM = pd.crosstab(Y_test,KNN_Pred)\n",
    "AS = accuracy_score(Y_test, KNN_Pred)*100\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FNR = FN/(FN+TP)\n",
    "print(CM)\n",
    "print(FNR)\n",
    "print(AS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "NB_model = GaussianNB().fit(X_train, Y_train)\n",
    "NB_pred = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the Naive Bayes model\n",
    "CM = pd.crosstab(Y_test,NB_pred)\n",
    "AS = accuracy_score(Y_test, NB_pred)*100\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FNR = FN/(FN+TP)\n",
    "print(CM)\n",
    "print(FNR)\n",
    "print(AS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
